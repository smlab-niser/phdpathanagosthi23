<html>

<head>
    <title>Subhankar Mishra | PhD Summer Pathana Gosthi 2023</title>
    <link href="https://www.niser.ac.in/~smishra/css/smlab.css" rel="stylesheet" type="text/css">
    <link href="style.css" rel="stylesheet" type="text/css">

    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <div class="container">
        <header>
            <h1>SUBHANKAR MISHRA</h1>
            <h2>ଶୁଭଙ୍କର ମିଶ୍ର</h2>
        </header>
        <p>
            Reader-F, School of Computer Sciences, NISER <br>
            ପାଠକ-ଏଫ, ସଂଗଣକ ବିଜ୍ଞାନ ବିଦ୍ୟାଳୟ, ନାଇଜର <br>
        </p>
        <hr /> <br>
        <div class="item">
            <h2> ପିଏଚ୍.ଡି. ଗ୍ରୀଷ୍ମ ପଠନ ଗୋଷ୍ଠୀ ୨୦୨୩ <br> PhD Summer Reading Group 2023</h2>
        </div>

        <img class="logo" src="logo.png">

        Welcome to PhD Pathana Gosthi, hosted by SM-LAB at the National Institute of Science Education and Research
        (NISER) in Odisha! This exciting event, taking place from <strong>June 12th</strong> to <strong>June 17th,
            2023</strong>, brings together PhD students in Machine Learning for a week of knowledge sharing and
        collaboration.<br><br>

        
        <h4>Schedule (Tentative)</h4>

        <!-- <details>
            <summary>Mon June 12, 2023</summary>
            <p>
            <table>
                <thead>
                    <tr>
                        <th>Time</th>
                        <th>Speaker</th>
                        <th>Topic</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>8:30am</td>
                        <td>Rucha</td>
                        <td>On the Expressive Power of Geometric Graph Neural Networks</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Annada</td>
                        <td>ReLU Fields: The Little Non-linearity That Could</td>
                    </tr>
                    <tr>
                        <td>11:30am</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>12:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Neha</td>
                        <td>Improving Social Network Embedding via New Second Order Continuous Graph Neural Networks
                        </td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Monalisha</td>
                        <td>Masked Auto-Encoders Meet Generative Adversarial Networks and Beyond</td>
                    </tr>
                    <tr>
                        <td>4:30pm</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>5:00pm</td>
                         <td></td>
                        <td>Tea break</td>
                    </tr>
                    <tr>
                        <td>5:30pm</td>
                        <td>Sujoy</td>
                        <td>Knowledge-enhanced Black-box Attacks for Recommendations</td>
                    </tr>
                </tbody>
            </table>
            </p>
        </details>
        <details>
            <summary>Tue June 13, 2023</summary>
            <p>
            <table>
                <thead>
                    <tr>
                        <th>Time</th>
                        <th>Speaker</th>
                        <th>Topic</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>8:30am</td>
                        <td>Pranita</td>
                        <td>Describing Differences between Text Distributions with Natural Language</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Niranjan</td>
                        <td>Symmetric Machine Theory of Mind</td>
                    </tr>
                    <tr>
                        <td>11:30am</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>12:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Pradeep</td>
                        <td>Knowledge-enhanced Black-box Attacks for Recommendations</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Monalisha</td>
                        <td>Deep Representations for Time-varying Brain Datasets</td>
                    </tr>
                    <tr>
                        <td>4:30pm</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>5:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                </tbody>
            </table>
            </p>
        </details>
        <details>
            <summary>Wed June 14, 2023</summary>
            <p>
            <table>
                <thead>
                    <tr>
                        <th>Time</th>
                        <th>Speaker</th>
                        <th>Topic</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>8:30am</td>
                        <td>Annada</td>
                        <td>Dr.Jit A Just-ln-Time Compiler for Differentiable Rendering</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Niranjan</td>
                        <td>Differentiable Top-k Classification Learning</td>
                    </tr>
                    <tr>
                        <td>11:30am</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>12:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Sujoy</td>
                        <td>A Large Scale Search Dataset for Unbiased Learning to Rank</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Neha</td>
                        <td>AdaAX : Explaining Recurrent Neural Networks by Learning Automata with Adaptive States</td>
                    </tr>
                    <tr>
                        <td>4:30pm</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>5:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                    <tr>
                        <td>5:30pm</td>
                        <td>Pradeep</td>
                        <td>Learning to Learn Transferable Attack</td>
                    </tr>
                </tbody>
            </table>
            </p>
        </details>
        <details>
            <summary>Thu June 15, 2023</summary>
            <p>
            <table>
                <thead>
                    <tr>
                        <th>Time</th>
                        <th>Speaker</th>
                        <th>Topic</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>8:30am</td>
                        <td>Sujoy</td>
                        <td>Revisiting Injective Attacks on Recommender Systems</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Pradeep</td>
                        <td>Deceptive Decision-Making under Uncertainty</td>
                    </tr>
                    <tr>
                        <td>11:30am</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>12:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Pranita</td>
                        <td>Self-Supervised Models of Audio Effectively Explain Human Cortical Responses to Speech</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Niranjan</td>
                        <td>Be Like Water: Adaptive Floating Point for Machine Learning</td>
                    </tr>
                    <tr>
                        <td>4:30pm</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>5:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                </tbody>
            </table>
            </p>
        </details>
        <details>
            <summary>Fri June 16, 2023</summary>
            <p>
            <table>
                <thead>
                    <tr>
                        <th>Time</th>
                        <th>Speaker</th>
                        <th>Topic</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>8:30am</td>
                        <td>Annada</td>
                        <td>Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and
                            Denoising</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Rucha</td>
                        <td>Rethinking Graph Lottery Tickets: Graph Sparsity Matters</td>
                    </tr>
                    <tr>
                        <td>11:30am</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>12:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Monalisha</td>
                        <td>Do we really need complicated model architectures for temporal Networks??</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td><i>Prof. Venkatesh Kamat</i></td>
                        <td><i>PhD Life: Before and after</i></td>
                    </tr>
                    <tr>
                        <td>4:30pm</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>5:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                </tbody>
            </table>
            </p>
        </details>
        <details>
            <summary>Sat June 17, 2023</summary>
            <p>
            <table>
                <thead>
                    <tr>
                        <th>Time</th>
                        <th>Speaker</th>
                        <th>Topic</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>8:30am</td>
                        <td>Rucha</td>
                        <td>Graph Neural Networks can Recover the Hidden Features Solely from the Graph Structure</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td><i>Prof. Vasudeva Siruguri</i></td>
                        <td><i>Research ethics</i></td>
                    </tr>
                    <tr>
                        <td>11:30am</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>12:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Neha</td>
                        <td>Towards Understanding Ensemble, Knowledge Distillation and Self Distillation in Deep
                            Learning</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Pranita</td>
                        <td>A Deep Leaming Approach for the Segmentation of Electroencephalography Data in Eye Tracking
                            Applications</td>
                    </tr>
                    <tr>
                        <td>4:30pm</td>
                         <td></td>
                        <td>Discussion</td>
                    </tr>
                    <tr>
                        <td>5:00pm</td>
                         <td></td>
                        <td>Lunch break</td>
                    </tr>
                </tbody>
            </table>
            </p>
        </details> -->


        <table><thead><tr><th>Date</th><th>Time</th><th>Speaker</th><th>Topic</th></tr></thead><tbody><tr><td rowspan="5">Mon, June 12 2023</td><td>8:30am</td><td>Rucha</td><td>On the Expressive Power of Geometric Graph Neural Networks</td></tr><tr><td>10:00am</td><td>Annada</td><td>ReLU Fields: The Little Non-linearity That Could</td></tr><tr><td>1:30pm</td><td>Neha</td><td>Improving Social Network Embedding via New Second Order Continuous Graph Neural Networks</td></tr><tr><td>3:00pm</td><td>Monalisha</td><td>Masked Auto-Encoders Meet Generative Adversarial Networks and Beyond</td></tr><tr><td>5:30pm</td><td>Sujoy</td><td>Knowledge-enhanced Black-box Attacks for Recommendations</td></tr><tr><td rowspan="4">Tue, June 13 2023</td><td>8:30am</td><td>Pranita</td><td>Describing Differences between Text Distributions with Natural Language</td></tr><tr><td>10:00am</td><td>Niranjan</td><td>Symmetric Machine Theory of Mind</td></tr><tr><td>1:30pm</td><td>Pradeep</td><td>Knowledge-enhanced Black-box Attacks for Recommendations</td></tr><tr><td>3:00pm</td><td>Monalisha</td><td>Deep Representations for Time-varying Brain Datasets</td></tr><tr><td rowspan="5">Wed, June 14 2023</td><td>8:30am</td><td>Annada</td><td>Dr.Jit A Just-ln-Time Compiler for Differentiable Rendering</td></tr><tr><td>10:00am</td><td>Niranjan</td><td>Differentiable Top-k Classification Learning</td></tr><tr><td>1:30pm</td><td>Sujoy</td><td>A Large Scale Search Dataset for Unbiased Learning to Rank</td></tr><tr><td>3:00pm</td><td>Neha</td><td>AdaAX : Explaining Recurrent Neural Networks by Learning Automata with Adaptive States</td></tr><tr><td>5:30pm</td><td>Pradeep</td><td>Learning to Learn Transferable Attack</td></tr><tr><td rowspan="4">Thu, June 15 2023</td><td>8:30am</td><td>Sujoy</td><td>Revisiting Injective Attacks on Recommender Systems</td></tr><tr><td>10:00am</td><td>Pradeep</td><td>Deceptive Decision-Making under Uncertainty</td></tr><tr><td>1:30pm</td><td>Pranita</td><td>Self-Supervised Models of Audio Effectively Explain Human Cortical Responses to Speech</td></tr><tr><td>3:00pm</td><td>Niranjan</td><td>Be Like Water: Adaptive Floating Point for Machine Learning</td></tr><tr><td rowspan="4">Fri, June 16 2023</td><td>8:30am</td><td>Annada</td><td>Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and Denoising</td></tr><tr><td>10:00am</td><td>Rucha</td><td>Rethinking Graph Lottery Tickets: Graph Sparsity Matters</td></tr><tr><td>1:30pm</td><td>Monalisha</td><td>DO WE REALLY NEED COMPLICATED MODEL ARCHITECTURES FOR TEMPORAL NETWORKS?</td></tr><tr><td>3:00pm</td><td>Prof. Venkatesh Kamat</td><td>PhD Life: Before and after</td></tr><tr><td rowspan="4">Sat, June 17 2023</td><td>8:30am</td><td>Rucha</td><td>Graph Neural Networks can Recover the Hidden Features Solely from the Graph Structure</td></tr><tr><td>10:00am</td><td>Prof. Vasudeva Siruguri</td><td>Research ethics</td></tr><tr><td>1:30pm</td><td>Neha</td><td>Towards Understanding Ensemble, Knowledge Distillation and Self Distillation in Deep Learning</td></tr><tr><td>3:00pm</td><td>Pranita</td><td>A Deep Leaming Approach for the Segmentation of Electroencephalography Data in Eye Tracking Applications</td></tr></tbody></table>

        <br>
        
        Apply Here: <a target="_blank" href="https://forms.gle/4FqrpKDNubJRo7yv8">Google Form</a></li>

        <h4>What is expected of you?</h4>
        <p>At PhD Pathana Gosthi, we expect selected PhD students to present recent papers from top conferences such as
            AAAI 2023,
            <a target="_blank" href="https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers">CVPR 2023</a>,
            <a target="_blank" href="https://openreview.net/group?id=ICLR.cc/2023/Conference">ICLR 2023</a>,
            <a target="_blank" href="https://icml.cc/Conferences/2022/Schedule">ICML 2022</a>,
            <a target="_blank" href="https://kdd.org/kdd2022/paperRT.html">KDD 2022</a>,
            <a target="_blank" href="https://nips.cc/Conferences/2022/Schedule">NeurIPS 2022</a>, and
            <a target="_blank" href="https://dl.acm.org/doi/proceedings/10.1145/3528233">SIGGRAPH 2022</a>.
            You will have the opportunity to suggest three papers of your choice while applying, and may be requested to
            present alternate papers if needed. The event aims to foster learning, discussion, and collaboration among
            PhD students, providing a platform for you to showcase your research and engage in meaningful discussions
            with fellow peers.
        </p>

        <h4>How will you be selected?</h4>
        <p>To participate in PhD Pathana Gosthi, PhD students need to submit their CV and Motivation Letter by filling
            up <a target="_blank" href="https://forms.gle/4FqrpKDNubJRo7yv8">this</a> form. Our selection process will
            involve shortlisting candidates based on their CV and Motivation Letter, and the chosen participants will be
            notified via email.</p>

        <h4>What will be provided?</h4>
        <p>PhD Pathana Gosthi provides selected PhD students with accommodation, meals, travel expenses, and a
            comprehensive kit and a certificate of
            participation. These provisions aim to ensure a comfortable and engaging experience, allowing participants
            to fully participate in the event and showcase their research.</p>

        This website will serve as a hub for information and updates about the event, as well as a platform for students
        to submit their application materials. Join us for this enriching experience as we delve into the cutting-edge
        world of Machine Learning and explore the latest advancements in the field!


        <h3>Resources</h3>
        <ul>
            <li><a target="_blank" href="./PhD_PathanaGhosthi_NOC.pdf">NOC Certificate Template</a></li>
        </ul>

        <h3>Important Dates</h3>
        <table>
            <thead>
                <tr>
                    <th>Event</th>
                    <th>Date</th>
                </tr>
            </thead>
            <tbody class="table-group-divider">
                <tr>
                    <td><s>Invitation emails sent to Institutions</s></td>
                    <td><s>April 10th, 2023</s></td>
                </tr>
                <tr>
                    <td><s>Last date of receiving application</s></td>
                    <td><s>May 12th <s>8th</s>, 2023</s></td>
                </tr>
                <tr>
                    <td><s>Acceptance Notification</s></td>
                    <td><s>May 15th, 2023</s></td>
                </tr>
                <tr>
                    <td><s>Confirmation email deadline for selected candidates</s></td>
                    <td><s>May 17th, 2023</s></td>
                </tr>
                <tr>
                    <td>Event Starts</td>
                    <td>June 12th, 2023</td>
                </tr>
                <tr>
                    <td>Event Ends</td>
                    <td>June 17th, 2023</td>
                </tr>
            </tbody>
        </table>


        <h3>Team</h3>
        <ul>
            <li>Annada Prasad Behera</li>
            <li>Aritra Mukhopadhyay</li>
            <li><a target="_blank" href="https://ruchajoshi.github.io">Rucha Bhalchandra Joshi</a></li>
            <li>Shradhanjali Sahoo</li>
            <li>Subhankar Mishra</li>
        </ul>


        <h4>How to reach NISER?</h4>
        <p>NISER is easily accessible from Khurda Junction railway station, Bhubaneswar bus to Jatni, or Biju Patnaik
            International Airport via taxi or public transport.</p>

        <p></p><strong>Address:</strong><br>
        Subhankar Mishra's Lab, School of Computer Sciences, NISER 752050.<br>
        Google Maps: <a href="https://goo.gl/maps/AuzSH3HaKpMijFTZ7">SM Lab</a><br>
        Email : <a href="mailto:ml-reading-group@niser.ac.in">ml-reading-group@niser.ac.in</a></p>



        <br><br><br>
        <div class="navbar">
            <a href="https://www.niser.ac.in/~smishra/index.html">Home</a>
            <a href="https://www.niser.ac.in/~smishra/people.html">People</a>
            <a href="https://www.niser.ac.in/~smishra/research.html">Research</a>
            <a href="https://www.niser.ac.in/~smishra/teaching.html">Teaching</a>
            <a href="https://www.niser.ac.in/~smishra/events.html" class="active">Events</a>
        </div>
    </div>
</body>

</html>