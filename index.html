<html>

<head>
    <title>Subhankar Mishra | PhD Summer Pathana Gosthi 2023</title>
    <link href="https://www.niser.ac.in/~smishra/css/smlab.css" rel="stylesheet" type="text/css">
    <link href="style.css" rel="stylesheet" type="text/css">

    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <div class="container">
        <header>
            <h1>SUBHANKAR MISHRA</h1>
            <h2>ଶୁଭଙ୍କର ମିଶ୍ର</h2>
        </header>
        <p>
            Reader-F, School of Computer Sciences, NISER <br>
            ପାଠକ-ଏଫ, ସଂଗଣକ ବିଜ୍ଞାନ ବିଦ୍ୟାଳୟ, ନାଇଜର <br>
        </p>
        <hr /> <br>
        <div class="item">
            <h2> ପିଏଚ୍.ଡି. ଗ୍ରୀଷ୍ମ ପଠନ ଗୋଷ୍ଠୀ ୨୦୨୩ <br> PhD Summer Reading Group 2023</h2>
        </div>

        <img class="logo" src="logo.png">

        Welcome to PhD Pathana Gosthi, hosted by SM-LAB at the National Institute of Science Education and Research
        (NISER) in Odisha! This exciting event, taking place from <strong>June 12th</strong> to <strong>June 17th,
            2023</strong>, brings together PhD students in Machine Learning for a week of knowledge sharing and
        collaboration.<br><br>
        <h3>Phase 2</h3>
        <h4>Schedule March 22, 2024</h4>
        <ol>
            <li><strong>Saumya Shankar</a></strong>
                <small>
                    <em>IIT Bhubaneswar</em>
                    <ul>
                        <li>Title: Advancements in Runtime Enforcement Frameworks: Finite Memory, Compositional
                            Approaches, and Practical Applications</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> In my work, we work on formal runtime enforcement approaches which monitor the
                                    execution of a system at runtime and ensure its compliance against a set of formal
                                    requirements. An enforcer can be considered as a safety wrapper for the system,
                                    (operating next to the execution of untrusted programs), which intervenes when an
                                    execution is about to violate the property being enforced. It catches the
                                    (untrustworthy) inputs (in the form of a sequence of events) and modifies those into
                                    an output sequence that complies with the specified property. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong>Jyotirmaya Shivottam</a></strong>
                <small>
                    <em>NISER</em>
                    <ul>
                        <li>Title: Graph Mamba</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> In this work, we explore State Space Models (SSMs) to improve long-range performance
                                    of Graph Neural Network models on various tasks. We formulate a new approach that
                                    incorporates SSMs into the message creation and updation step in Graph Neural
                                    Networks, and perform several experiments to verify whether this approach leads to
                                    better performance on a set of standard datasets. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong>Kamakshya Prasad Nayak</a></strong>
                <small>
                    <em>IIT Bhubaneswar</em>
                    <ul>
                        <li>Title: Gaze based analysis of small conversational groups</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> Gaze is critical for applications like human social behaviour analysis, visual
                                    navigation, action recognition, human-robot interaction, autism research etc. Gaze
                                    target detection or gaze following aims at estimating the person or object at which
                                    any subject is looking. Given an input video, the objective is to verify certain
                                    hypothesis in movie/series data as well as publicly available video which are
                                    natural and not recorded under guidance or supervision. Precisely, we perform the
                                    gaze analysis relating to the variation in the number of people in the scene and
                                    context under which the discussion is taking place. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong>Rojalini Tripathy</a></strong>
                <small>
                    <em>IIT Bhubaneswar</em>
                    <ul>
                        <li>Title: Privacy Preserving Peer-to-Peer Federated Learning</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> Federated learning (FL) is an emerging technology that acquires significant
                                    attention by the research community due to its manyfold advantages and applications.
                                    FL is an area of Machine Learning(ML) that enables multiple data owners to
                                    collaboratively train a single model by exchanging model parameters instead of
                                    original data. This allows enforcing security and privacy of data as well as
                                    provides effective ways of employing AI techniques in different applications.
                                    Despite its advantages, FL faces challenges such as dependency on a central server,
                                    slow convergence, and impact of message exchanges on system efficiency. In this
                                    paper, we are proposing a peer-to-peer federated learning framework using secure
                                    multiparty computation. Our proposed framework makes FL not dependent on a central
                                    server and provides secure parameter sharing. We have implemented our proposed
                                    framework with two different datasets, considering different numbers of clients, and
                                    analyzed it. We observe that our framework performs better than existing frameworks.
                                </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong>Kasturi Routray</a></strong>
                <small>
                    <em>IIT Bhubaneswar</em>
                    <ul>
                        <li>Title: Context-Aware Attribute Based Access Control for Cloud-based SCADA Systems</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> Cloud-based SCADA (Supervisory Control and Data Acquisition) systems enable seamless
                                    access to internet of things (IoT) operational data for employees at control
                                    facilities and operators working on the field for automated control and monitoring
                                    of industrial infrastructure. In this work, we introduced a novel approach based on
                                    ciphertext policy attribute-based encryption (CP-ABE) to ensure secure and
                                    fine-grained access control over data stored in the cloud. Our proposed scheme
                                    considers static and dynamic attributes of the users to devise an access policy.
                                    Contextual locks are introduced for defining constraints on dynamic attributes.
                                    These locks are independent of the user's attribute sets; thus, they don't require
                                    decryption keys to be associated with dynamic attributes. This avoids system
                                    overhead with frequent changes in contextual parameters. To protect the
                                    confidentiality of the access policy, we obfuscate its attributes during the
                                    data-sharing process. Moreover, our proposed scheme prevents key escrow attacks on
                                    cloud-stored data. Additionally, fog servers are employed to verify the user's
                                    contextual attributes and reduce the computational overhead of decryption for end
                                    users. Our scheme enhances the security and integrity of remote process control and
                                    monitoring in industrial systems while leveraging the benefits of real-time data
                                    analysis and decision-making. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
        </ol>

        <h3>Phase 1</h3>

        Speakers : Rucha Bhalchandra Joshi (NISER), Annada Prasad Behera (NISER), Neha (XIMB) 
        <br>
        
        <details>
            <summary>Tentative schedule - </summary>
            <p>
            <h4></h4>

            <table>
                <thead>
                    <tr>
                        <th>Date</th>
                        <th>Time</th>
                        <th>Speaker</th>
                        <th>Topic</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td rowspan="5">Mon, June 12 2023</td>
                        <td>8:30am</td>
                        <td>Rucha</td>
                        <td>On the Expressive Power of Geometric Graph Neural Networks</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td><i> Dr. Praneeth Netrapali</i></td>
                        <td><i>Towards neural networks robust to distribution shifts</i></td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Neha</td>
                        <td>Improving Social Network Embedding via New Second Order Continuous Graph Neural Networks
                        </td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Monalisha</td>
                        <td>Masked Auto-Encoders Meet Generative Adversarial Networks and Beyond</td>
                    </tr>
                    <tr>
                        <td>5:30pm</td>
                        <td>Sujoy</td>
                        <td>Knowledge-enhanced Black-box Attacks for Recommendations</td>
                    </tr>
                    <tr>
                        <td rowspan="5">Tue, June 13 2023</td>
                        <td>8:30am</td>
                        <td>Pranita</td>
                        <td>Describing Differences between Text Distributions with Natural Language</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Niranjan</td>
                        <td>Symmetric Machine Theory of Mind</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Pradeep</td>
                        <td>Knowledge-enhanced Black-box Attacks for Recommendations</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Monalisha</td>
                        <td>Deep Representations for Time-varying Brain Datasets</td>
                    </tr>
                    <tr>
                        <td>5:30pm</td>
                        <td>Annada</td>
                        <td>ReLU Fields: The Little Non-linearity That Could</td>
                    </tr>
                    <tr>
                        <td rowspan="5">Wed, June 14 2023</td>
                        <td>8:30am</td>
                        <td>Annada</td>
                        <td>Dr.Jit A Just-ln-Time Compiler for Differentiable Rendering</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Niranjan</td>
                        <td>Differentiable Top-k Classification Learning</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Sujoy</td>
                        <td>A Large Scale Search Dataset for Unbiased Learning to Rank</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Neha</td>
                        <td>AdaAX : Explaining Recurrent Neural Networks by Learning Automata with Adaptive States</td>
                    </tr>
                    <tr>
                        <td>5:30pm</td>
                        <td>Pradeep</td>
                        <td>Learning to Learn Transferable Attack</td>
                    </tr>
                    <tr>
                        <td rowspan="4">Thu, June 15 2023</td>
                        <td>8:30am</td>
                        <td>Sujoy</td>
                        <td>Revisiting Injective Attacks on Recommender Systems</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Pradeep</td>
                        <td>Deceptive Decision-Making under Uncertainty</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Pranita</td>
                        <td>Self-Supervised Models of Audio Effectively Explain Human Cortical Responses to Speech</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Niranjan</td>
                        <td>Be Like Water: Adaptive Floating Point for Machine Learning</td>
                    </tr>
                    <tr>
                        <td rowspan="4">Fri, June 16 2023</td>
                        <td>8:30am</td>
                        <td>Annada</td>
                        <td>Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and
                            Denoising
                        </td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td>Rucha</td>
                        <td>Rethinking Graph Lottery Tickets: Graph Sparsity Matters</td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Monalisha</td>
                        <td>Do We Really Need Complicated Model Architectures for Temporal Networks?</td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td><i>Prof. Venkatesh Kamat</i></td>
                        <td><i>Some myths and facts about PhD Life and the Future</i></td>
                    </tr>
                    <tr>
                        <td rowspan="4">Sat, June 17 2023</td>
                        <td>8:30am</td>
                        <td>Rucha</td>
                        <td>Graph Neural Networks can Recover the Hidden Features Solely from the Graph Structure</td>
                    </tr>
                    <tr>
                        <td>10:00am</td>
                        <td><i>Prof. Vasudeva Siruguri</i></td>
                        <td><i>Technological advances and Ethical Impacts</i></td>
                    </tr>
                    <tr>
                        <td>1:30pm</td>
                        <td>Neha</td>
                        <td>Towards Understanding Ensemble, Knowledge Distillation and Self Distillation in Deep
                            Learning
                        </td>
                    </tr>
                    <tr>
                        <td>3:00pm</td>
                        <td>Pranita</td>
                        <td>A Deep Leaming Approach for the Segmentation of Electroencephalography Data in Eye Tracking
                            Applications</td>
                    </tr>
                </tbody>
            </table>
            </p>
        </details>

        <br>

        Apply Here: <a target="_blank" href="https://forms.gle/4FqrpKDNubJRo7yv8">Google Form</a></li>

        <h4>What is expected of you?</h4>
        <p>At PhD Pathana Gosthi, we expect selected PhD students to present recent papers from top conferences such as
            AAAI 2023,
            <a target="_blank" href="https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers">CVPR 2023</a>,
            <a target="_blank" href="https://openreview.net/group?id=ICLR.cc/2023/Conference">ICLR 2023</a>,
            <a target="_blank" href="https://icml.cc/Conferences/2022/Schedule">ICML 2022</a>,
            <a target="_blank" href="https://kdd.org/kdd2022/paperRT.html">KDD 2022</a>,
            <a target="_blank" href="https://nips.cc/Conferences/2022/Schedule">NeurIPS 2022</a>, and
            <a target="_blank" href="https://dl.acm.org/doi/proceedings/10.1145/3528233">SIGGRAPH 2022</a>.
            You will have the opportunity to suggest three papers of your choice while applying, and may be requested to
            present alternate papers if needed. The event aims to foster learning, discussion, and collaboration among
            PhD students, providing a platform for you to showcase your research and engage in meaningful discussions
            with fellow peers.
        </p>

        <h4>How will you be selected?</h4>
        <p>To participate in PhD Pathana Gosthi, PhD students need to submit their CV and Motivation Letter by filling
            up <a target="_blank" href="https://forms.gle/4FqrpKDNubJRo7yv8">this</a> form. Our selection process will
            involve shortlisting candidates based on their CV and Motivation Letter, and the chosen participants will be
            notified via email.</p>

        <h4>What will be provided?</h4>
        <p>PhD Pathana Gosthi provides selected PhD students with accommodation, meals, travel expenses, and a
            comprehensive kit and a certificate of
            participation. These provisions aim to ensure a comfortable and engaging experience, allowing participants
            to fully participate in the event and showcase their research.</p>

        This website will serve as a hub for information and updates about the event, as well as a platform for students
        to submit their application materials. Join us for this enriching experience as we delve into the cutting-edge
        world of Machine Learning and explore the latest advancements in the field!


        <h3>Resources</h3>
        <ul>
            <li><a target="_blank" href="./PhD_PathanaGhosthi_NOC.pdf">NOC Certificate Template</a></li>
        </ul>

        <h3>Important Dates</h3>
        <table>
            <thead>
                <tr>
                    <th>Event</th>
                    <th>Date</th>
                </tr>
            </thead>
            <tbody class="table-group-divider">
                <tr>
                    <td><s>Invitation emails sent to Institutions</s></td>
                    <td><s>April 10th, 2023</s></td>
                </tr>
                <tr>
                    <td><s>Last date of receiving application</s></td>
                    <td><s>May 12th <s>8th</s>, 2023</s></td>
                </tr>
                <tr>
                    <td><s>Acceptance Notification</s></td>
                    <td><s>May 15th, 2023</s></td>
                </tr>
                <tr>
                    <td><s>Confirmation email deadline for selected candidates</s></td>
                    <td><s>May 17th, 2023</s></td>
                </tr>
                <tr>
                    <td><s>Event Starts</s></td>
                    <td><s>June 12th, 2023</s></td>
                </tr>
                <tr>
                    <td><s>Event Ends</s></td>
                    <td><s>June 17th, 2023</s></td>
                </tr>
            </tbody>
        </table>


        <h3>Team</h3>
        <ul>
            <li>Annada Prasad Behera</li>
            <li>Aritra Mukhopadhyay</li>
            <li><a target="_blank" href="https://ruchajoshi.github.io">Rucha Bhalchandra Joshi</a></li>
            <li>Shradhanjali Sahoo</li>
            <li>Subhankar Mishra</li>
        </ul>


        <h4>How to reach NISER?</h4>
        <p>NISER is easily accessible from Khurda Junction railway station, Bhubaneswar bus to Jatni, or Biju Patnaik
            International Airport via taxi or public transport.</p>

        <p></p><strong>Address:</strong><br>
        Subhankar Mishra's Lab, School of Computer Sciences, NISER 752050.<br>
        Google Maps: <a href="https://goo.gl/maps/AuzSH3HaKpMijFTZ7">SM Lab</a><br>
        Email : <a href="mailto:ml-reading-group@niser.ac.in">ml-reading-group@niser.ac.in</a></p>



        <br><br><br>
        <div class="navbar">
            <a href="https://www.niser.ac.in/~smishra/index.html">Home</a>
            <a href="https://www.niser.ac.in/~smishra/people.html">People</a>
            <a href="https://www.niser.ac.in/~smishra/research.html">Research</a>
            <a href="https://www.niser.ac.in/~smishra/teaching.html">Teaching</a>
            <a href="https://www.niser.ac.in/~smishra/events.html" class="active">Events</a>
        </div>
    </div>
</body>

</html>